import { checkRateLimit, addRateLimitHeaders } from '../lib/rateLimit.js';
import { handleCORS } from '../lib/corsConfig.js';

/**
 * TECHNIQUE D'INJECTION √âMOTIONNELLE ELEVENLABS (CORRIG√âE)
 *
 * Le next_text doit √™tre COURT - comme une didascalie de sc√©nario.
 * Le texte principal est entre guillemets pour simuler un dialogue lu.
 * Ajout du language_code pour forcer le fran√ßais canadien.
 *
 * Sources:
 * - https://elevenlabs.io/docs/api-reference/text-to-speech/convert
 * - https://elevenlabs.io/docs/best-practices/prompting/controls
 */

// Contexte √©motionnel COURT pour m√©ditation (voix Iza)
// Format: comme si on lisait un livre avec indication de jeu
// IMPORTANT: Mention explicite "qu√©b√©coise" pour ancrer l'accent
const MEDITATION_EMOTIONAL_CONTEXT = {
  // Texte qui "pr√©c√®de" - √©tablit le contexte √©motionnel initial (COURT)
  // Mention "qu√©b√©coise" pour ancrer l'accent d√®s le d√©part
  previous_text: `La guide qu√©b√©coise ferme les yeux, respirant lentement.`,
  // Texte qui "suit" - indique COMMENT le texte est prononc√© (COURT - cl√©!)
  // Ton calme et pos√©, sans √©nergie excessive
  next_text: `, murmure-t-elle tout bas, gardant son calme jusqu'√† la fin.`
};

// Contexte √©motionnel COURT pour r√©flexion (voix Dann)
const REFLECTION_EMOTIONAL_CONTEXT = {
  previous_text: `Il te regarde avec bienveillance.`,
  next_text: `, dit-il d'un ton pos√© et r√©fl√©chi.`
};

export default async function handler(req, res) {
  // üîê CORS S√âCURIS√â - Whitelist origines autoris√©es
  if (!handleCORS(req, res)) {
    return; // Bloqu√© ou OPTIONS trait√©
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // ‚ö° RATE LIMITING - Protection contre les abus
  const rateLimit = checkRateLimit(req, '/api/audio');
  addRateLimitHeaders(res, { ...rateLimit, endpoint: '/api/audio' });

  if (!rateLimit.allowed) {
    console.warn(`üö´ Rate limit exceeded for audio - IP: ${req.headers['x-forwarded-for'] || 'unknown'}`);
    return res.status(429).json({
      error: 'Too Many Requests',
      message: rateLimit.message,
      retryAfter: rateLimit.retryAfter
    });
  }

  console.log(`‚úÖ Rate limit check passed - Remaining: ${rateLimit.remaining}/${15}`);

  /**
   * Pr√©pare le texte pour la synth√®se vocale
   * - Entoure de guillemets (technique dialogue lu)
   * - Ajoute VRAIES pauses SSML entre paragraphes (4s = 2x 2s car max 3s)
   * - Pauses courtes entre lignes
   */
  function prepareText(text, isMeditation) {
    // Nettoyage du texte
    text = text.replace(/\.\.\./g, '... '); // Ellipses naturelles

    // PAUSES SSML pour m√©ditation (4 secondes entre paragraphes)
    // ElevenLabs max = 3s, donc on utilise 2x 2s pour 4 secondes
    if (isMeditation) {
      text = text.replace(/\n\n+/g, '. <break time="2s"/><break time="2s"/> ');
      text = text.replace(/\n/g, '. <break time="0.8s"/> ');
    } else {
      // R√©flexion: pauses plus courtes
      text = text.replace(/\n\n+/g, '. <break time="1.5s"/> ');
      text = text.replace(/\n/g, '. <break time="0.5s"/> ');
    }

    // Entourer de guillemets pour simuler un dialogue lu
    // Cela permet au next_text d'agir comme une indication de jeu
    return `"${text}"`;
  }

  try {
    const { text, guideType } = req.body;

    if (!text) {
      return res.status(400).json({ error: 'Missing text field' });
    }

    const isMeditation = guideType !== 'reflection';

    // Pr√©parer le texte
    const processedText = prepareText(text, isMeditation);

    // Log complet des param√®tres envoy√©s √† ElevenLabs
    console.log('=== ELEVENLABS REQUEST CONFIG ===');
    console.log('Guide Type:', guideType);
    console.log('Voice ID:', guideType === 'reflection' ? '93nuHbke4dTER9x2pDwE (Dann)' : 'xsNzdCmWJpYoa80FaXJi (Iza)');
    console.log('Emotional Injection: ENABLED (short format)');
    console.log('Text wrapped in quotes: YES');
    console.log('Language Code: fr');
    console.log('Text preview:', processedText.substring(0, 100) + '...');
    console.log('=== END CONFIG ===');

    // Choisir la voix selon le type de guide
    const voiceId = guideType === 'reflection'
      ? '93nuHbke4dTER9x2pDwE'  // Voix masculine Dann pour r√©flexion
      : 'xsNzdCmWJpYoa80FaXJi';  // Voix f√©minine Iza (voix personnalis√©e)

    // S√©lectionner le contexte √©motionnel appropri√©
    const emotionalContext = isMeditation
      ? MEDITATION_EMOTIONAL_CONTEXT
      : REFLECTION_EMOTIONAL_CONTEXT;

    // Voice settings optimis√©s pour STABILIT√â D'ACCENT MAXIMALE
    // La technique next_text + guillemets g√®re le ton m√©ditatif
    // On peut donc pousser la stabilit√© au maximum pour l'accent
    const voiceSettings = guideType === 'reflection'
      ? {
          // DANN - R√©flexion socratique, conversationnel mais pos√©
          stability: 0.70,           // √âquilibr√©
          similarity_boost: 0.85,    // Bonne fid√©lit√©
          style: 0.05,               // Minimal - accent stable
          speed: 0.82,               // L√©g√®rement ralenti
          use_speaker_boost: true
        }
      : {
          // IZA - M√©ditation calme, ACCENT QU√âB√âCOIS ULTRA-STABLE
          // Stabilit√© MAXIMALE pour √©viter toute d√©rive d'accent ou de ton
          // Le ton m√©ditatif vient du next_text + guillemets
          stability: 0.95,           // MAXIMUM - accent qu√©b√©cois ultra-stable
          similarity_boost: 0.95,    // MAXIMUM - fid√©lit√© totale √† la voix originale
          style: 0.0,                // Z√âRO - aucune variation stylistique
          speed: 0.72,               // Plus lent pour √©viter acc√©l√©ration en fin de texte
          use_speaker_boost: true    // Clart√© vocale
        };

    // ElevenLabs API avec INJECTION √âMOTIONNELLE + LANGUAGE CODE
    // Technique combin√©e: guillemets + next_text court + stabilit√© max
    const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
      method: 'POST',
      headers: {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': process.env.ELEVENLABS_API_KEY
      },
      body: JSON.stringify({
        text: processedText,
        model_id: 'eleven_multilingual_v2',
        language_code: 'fr',           // Force le fran√ßais (aide stabilit√© accent)
        voice_settings: voiceSettings,
        // üé≠ INJECTION √âMOTIONNELLE - Didascalies courtes
        previous_text: emotionalContext.previous_text,
        next_text: emotionalContext.next_text,
        seed: 42,                       // Reproductibilit√©
        output_format: 'mp3_44100_192'
      })
    });

    if (!response.ok) {
      const errorBody = await response.text();
      console.error('ElevenLabs API error:', response.status, errorBody);
      throw new Error(`ElevenLabs API error: ${response.status} - ${errorBody}`);
    }

    const audioBuffer = await response.arrayBuffer();
    const base64Audio = Buffer.from(audioBuffer).toString('base64');

    res.status(200).json({ audio: base64Audio });

  } catch (error) {
    console.error('Error generating audio:', error);
    res.status(500).json({ error: 'Failed to generate audio', details: error.message });
  }
}
