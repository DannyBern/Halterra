import { checkRateLimit, addRateLimitHeaders } from '../lib/rateLimit.js';
import { handleCORS } from '../lib/corsConfig.js';

/**
 * TECHNIQUE D'INJECTION √âMOTIONNELLE ELEVENLABS
 *
 * Utilise previous_text et next_text pour injecter un contexte √©motionnel
 * sans que ce texte soit prononc√©. C'est comme si on lisait un livre
 * avec des didascalies/indications de jeu.
 *
 * Sources:
 * - https://elevenlabs.io/docs/capabilities/text-to-speech
 * - https://medium.com/@tommywilczek/how-to-add-emotion-to-ai-voices-elevenlabs-2025
 */

// Contexte √©motionnel pour m√©ditation (voix Iza)
const MEDITATION_EMOTIONAL_CONTEXT = {
  // Texte qui "pr√©c√®de" - √©tablit le ton initial
  previous_text: `Elle ferme les yeux, inspire profond√©ment, et commence √† parler d'une voix douce,
    calme et apaisante. Son ton est celui d'une guide de m√©ditation exp√©riment√©e,
    chaleureux et rassurant. Elle parle lentement, avec des pauses naturelles,
    comme si chaque mot √©tait une caresse pour l'√¢me. Sa voix qu√©b√©coise est
    enveloppante et maternelle.`,

  // Texte qui "suit" - renforce l'intention tout au long
  next_text: `murmure-t-elle doucement, sa voix restant calme et m√©ditative jusqu'√† la fin,
    comme une berceuse pour adulte. Elle maintient ce ton apaisant et bienveillant,
    guidant l'auditeur vers un √©tat de paix int√©rieure.`
};

// Contexte √©motionnel pour r√©flexion (voix Dann)
const REFLECTION_EMOTIONAL_CONTEXT = {
  previous_text: `Il s'adresse √† toi comme un ami sage et bienveillant. Sa voix est
    pos√©e, r√©fl√©chie, avec une pointe de curiosit√© sinc√®re. Il pose des questions
    qui invitent √† l'introspection, sans jugement.`,

  next_text: `dit-il d'un ton encourageant mais direct, t'invitant √† r√©fl√©chir
    avec lui plut√¥t que de te donner des r√©ponses toutes faites.`
};

export default async function handler(req, res) {
  // üîê CORS S√âCURIS√â - Whitelist origines autoris√©es
  if (!handleCORS(req, res)) {
    return; // Bloqu√© ou OPTIONS trait√©
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // ‚ö° RATE LIMITING - Protection contre les abus
  const rateLimit = checkRateLimit(req, '/api/audio');
  addRateLimitHeaders(res, { ...rateLimit, endpoint: '/api/audio' });

  if (!rateLimit.allowed) {
    console.warn(`üö´ Rate limit exceeded for audio - IP: ${req.headers['x-forwarded-for'] || 'unknown'}`);
    return res.status(429).json({
      error: 'Too Many Requests',
      message: rateLimit.message,
      retryAfter: rateLimit.retryAfter
    });
  }

  console.log(`‚úÖ Rate limit check passed - Remaining: ${rateLimit.remaining}/${15}`);

  /**
   * Pr√©pare le texte pour la synth√®se vocale
   * Ajoute des indices de ton via la ponctuation
   */
  function prepareText(text, isMeditation) {
    // Nettoyage du texte pour pauses naturelles via ponctuation
    text = text.replace(/\.\.\./g, '... '); // Ellipses naturelles
    text = text.replace(/\n\n+/g, '. ');    // Paragraphes ‚Üí pause longue
    text = text.replace(/\n/g, ', ');       // Lignes ‚Üí pause courte

    return text;
  }

  try {
    const { text, guideType } = req.body;

    if (!text) {
      return res.status(400).json({ error: 'Missing text field' });
    }

    const isMeditation = guideType !== 'reflection';

    // Pr√©parer le texte
    const processedText = prepareText(text, isMeditation);

    // Log du texte complet envoy√© √† ElevenLabs
    console.log('=== FULL TEXT SENT TO ELEVENLABS ===');
    console.log('Guide Type:', guideType);
    console.log('Emotional Context: ENABLED');
    console.log(processedText);
    console.log('=== END TEXT ===');

    // Choisir la voix selon le type de guide
    const voiceId = guideType === 'reflection'
      ? '93nuHbke4dTER9x2pDwE'  // Voix masculine Dann pour r√©flexion
      : 'xsNzdCmWJpYoa80FaXJi';  // Voix f√©minine Iza (voix personnalis√©e)

    // S√©lectionner le contexte √©motionnel appropri√©
    const emotionalContext = isMeditation
      ? MEDITATION_EMOTIONAL_CONTEXT
      : REFLECTION_EMOTIONAL_CONTEXT;

    // Voice settings optimis√©s pour TON M√âDITATIF STABLE
    // √âquilibre entre stabilit√© d'accent et expressivit√© minimale
    const voiceSettings = guideType === 'reflection'
      ? {
          // DANN - R√©flexion socratique, conversationnel mais pos√©
          stability: 0.65,           // √âquilibr√©
          similarity_boost: 0.80,    // Bonne fid√©lit√©
          style: 0.10,               // Tr√®s peu - √©vite variations excessives
          speed: 0.82,               // L√©g√®rement ralenti
          use_speaker_boost: true
        }
      : {
          // IZA - M√©ditation calme, douce, stable
          // L'injection √©motionnelle via previous_text/next_text
          // permet de r√©duire la stability tout en gardant le bon ton
          stability: 0.75,           // R√âDUIT - le contexte √©motionnel compense
          similarity_boost: 0.85,    // Bonne fid√©lit√© √† la voix
          style: 0.12,               // L√âG√àREMENT AUGMENT√â - pour douceur
          speed: 0.78,               // Lent et pos√©
          use_speaker_boost: true
        };

    // ElevenLabs API avec INJECTION √âMOTIONNELLE
    // previous_text et next_text donnent le contexte sans √™tre prononc√©s
    const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
      method: 'POST',
      headers: {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': process.env.ELEVENLABS_API_KEY
      },
      body: JSON.stringify({
        text: processedText,
        model_id: 'eleven_multilingual_v2',
        voice_settings: voiceSettings,
        // üé≠ INJECTION √âMOTIONNELLE - Le secret pour un ton consistant
        previous_text: emotionalContext.previous_text,
        next_text: emotionalContext.next_text,
        seed: 42,
        pronunciation_dictionary_locators: [],
        output_format: 'mp3_44100_192'
      })
    });

    if (!response.ok) {
      const errorBody = await response.text();
      console.error('ElevenLabs API error:', response.status, errorBody);
      throw new Error(`ElevenLabs API error: ${response.status} - ${errorBody}`);
    }

    const audioBuffer = await response.arrayBuffer();
    const base64Audio = Buffer.from(audioBuffer).toString('base64');

    res.status(200).json({ audio: base64Audio });

  } catch (error) {
    console.error('Error generating audio:', error);
    res.status(500).json({ error: 'Failed to generate audio', details: error.message });
  }
}
