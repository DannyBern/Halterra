import { checkRateLimit, addRateLimitHeaders } from '../lib/rateLimit.js';
import { handleCORS } from '../lib/corsConfig.js';

/**
 * ELEVENLABS V3 AVEC AUDIO TAGS POUR M√âDITATIONS EXPRESSIVES
 *
 * Utilise le mod√®le eleven_v3 (alpha) avec insertion automatique de:
 * - [breath] - respiration naturelle
 * - [sigh] - soupir apais√©
 * - [softly] - ton doux
 * - [pause] - pause naturelle
 *
 * Le mod√®le V3 interpr√®te ces tags pour produire des vocalisations
 * naturelles et expressives, id√©ales pour les m√©ditations guid√©es.
 *
 * Sources:
 * - https://elevenlabs.io/blog/v3-audiotags
 * - https://elevenlabs.io/blog/eleven-v3-alpha-now-available-in-the-api
 */

// ============================================================================
// CONFIGURATION
// ============================================================================

// Voix ElevenLabs
const VOICE_IDS = {
  meditation: 'xsNzdCmWJpYoa80FaXJi',  // Iza - voix f√©minine qu√©b√©coise
  reflection: '93nuHbke4dTER9x2pDwE'   // Dann - voix masculine
};

// Voice settings optimis√©s pour V3
// IMPORTANT: V3 accepte seulement stability: 0.0 (Creative), 0.5 (Natural), 1.0 (Robust)
const VOICE_SETTINGS = {
  meditation: {
    stability: 0.5,            // Natural - bon √©quilibre pour m√©ditation
    similarity_boost: 0.90,    // Haute fid√©lit√© √† la voix
    style: 0.0,                // Pas de style pour V3
    speed: 0.75,               // Lent pour m√©ditation
    use_speaker_boost: true
  },
  reflection: {
    stability: 0.5,            // Natural
    similarity_boost: 0.85,
    style: 0.0,
    speed: 0.85,
    use_speaker_boost: true
  }
};

// ============================================================================
// AUDIO TAGS POUR V3
// ============================================================================

/**
 * Ins√®re automatiquement des audio tags V3 dans le texte de m√©ditation
 *
 * Tags utilis√©s:
 * - [breath] - respiration naturelle (apr√®s les phrases d'inspiration)
 * - [sigh] - soupir apais√© (moments de rel√¢chement)
 * - [softly] - ton doux (passages intimes)
 * - [calmly] - ton calme (instructions)
 * - [gently] - ton doux et bienveillant
 * - [slowly] - ralentissement naturel
 *
 * Strat√©gie: Insertion contextuelle bas√©e sur le contenu du texte
 */
function insertAudioTags(text, isMeditation = true) {
  let processed = text;

  // Patterns pour m√©ditation - insertion de [breath] apr√®s phrases de respiration
  const breathPatterns = [
    /(\brespire[zs]?\b[^.]*\.)/gi,
    /(\binspire[zs]?\b[^.]*\.)/gi,
    /(\bexpire[zs]?\b[^.]*\.)/gi,
    /(\bsouffle\b[^.]*\.)/gi,
    /(\bprofond√©ment\b[^.]*\.)/gi
  ];

  breathPatterns.forEach(pattern => {
    processed = processed.replace(pattern, '$1 [breath]');
  });

  // Patterns pour [sigh] - moments de rel√¢chement
  const sighPatterns = [
    /(\brel√¢che[zs]?\b[^.]*\.)/gi,
    /(\bl√¢che[zs]?\b[^.]*\.)/gi,
    /(\bd√©tend[s]?[^.]*\.)/gi,
    /(\blaisse[zs]? aller\b[^.]*\.)/gi,
    /(\babandonne[zs]?\b[^.]*\.)/gi
  ];

  sighPatterns.forEach(pattern => {
    processed = processed.replace(pattern, '[sigh] $1');
  });

  // Ajouter [softly] au d√©but des paragraphes intimes
  const softPatterns = [
    /(\bDoucement\b)/gi,
    /(\bTout doucement\b)/gi,
    /(\bAvec douceur\b)/gi,
    /(\bTendrement\b)/gi
  ];

  softPatterns.forEach(pattern => {
    processed = processed.replace(pattern, '[softly] $1');
  });

  // Ajouter [calmly] pour les instructions calmes
  const calmPatterns = [
    /(\bMaintenant\b)/gi,
    /(\b√Ä pr√©sent\b)/gi,
    /(\bPrenez le temps\b)/gi,
    /(\bPrends le temps\b)/gi
  ];

  calmPatterns.forEach(pattern => {
    processed = processed.replace(pattern, '[calmly] $1');
  });

  // Ajouter [gently] pour les phrases bienveillantes
  const gentlePatterns = [
    /(\bAccueille[zs]?\b)/gi,
    /(\bPermets-toi\b)/gi,
    /(\bPermettez-vous\b)/gi,
    /(\bOffre[zs]?-toi\b)/gi,
    /(\bSois\b[^.]*bienveillant)/gi
  ];

  gentlePatterns.forEach(pattern => {
    processed = processed.replace(pattern, '[gently] $1');
  });

  // Ajouter [slowly] pour les moments de pause
  const slowPatterns = [
    /(\bPause\b)/gi,
    /(\bSilence\b)/gi,
    /(\bPrends? un moment\b)/gi,
    /(\bPrenez un moment\b)/gi
  ];

  slowPatterns.forEach(pattern => {
    processed = processed.replace(pattern, '[slowly] $1');
  });

  // Remplacer les ... par une pause naturelle
  processed = processed.replace(/\.\.\./g, '... [breath]');

  // Ajouter des respirations entre les paragraphes (doubles sauts de ligne)
  processed = processed.replace(/\n\n+/g, '\n\n[breath]\n\n');

  // Nettoyer les tags en double
  processed = processed.replace(/\[breath\]\s*\[breath\]/g, '[breath]');
  processed = processed.replace(/\[sigh\]\s*\[sigh\]/g, '[sigh]');

  console.log(`üè∑Ô∏è Audio tags inserted. Original: ${text.length} chars, With tags: ${processed.length} chars`);

  return processed;
}

/**
 * Pr√©pare le texte pour ElevenLabs V3
 * - Ins√®re les audio tags appropri√©s
 * - Nettoie le formatage
 * - Ajoute un contexte qu√©b√©cois pour ancrer l'accent
 */
function prepareTextForV3(text, isMeditation = true) {
  // Ins√©rer les audio tags
  let processed = insertAudioTags(text, isMeditation);

  // Nettoyer les sauts de ligne multiples
  processed = processed.replace(/\n{3,}/g, '\n\n');

  // Ajouter un pr√©ambule qu√©b√©cois invisible pour ancrer l'accent
  // Cette technique utilise previous_text conceptuellement via le texte lui-m√™me
  const quebecPrimer = isMeditation
    ? '[softly] '
    : '[warmly] ';

  processed = `${quebecPrimer}${processed}`;

  return processed.trim();
}

// ============================================================================
// G√âN√âRATION AUDIO V3
// ============================================================================

/**
 * G√©n√®re l'audio avec ElevenLabs V3
 *
 * Le mod√®le V3 est con√ßu pour:
 * - Interpr√©ter les audio tags [breath], [sigh], [softly], etc.
 * - Maintenir une meilleure coh√©rence sur les longs textes
 * - Produire des vocalisations naturelles et expressives
 *
 * @param text - Texte avec audio tags ins√©r√©s
 * @param voiceId - ID de la voix ElevenLabs
 * @param voiceSettings - Param√®tres de la voix
 * @returns Buffer audio MP3
 */
async function generateAudioV3(text, voiceId, voiceSettings) {
  console.log(`  üì§ Calling ElevenLabs V3 API...`);
  console.log(`  üìù Text length: ${text.length} chars`);

  // Utilise fr-CA pour forcer l'accent qu√©b√©cois
  // fr-CA = fran√ßais canadien (qu√©b√©cois) vs fr-FR = fran√ßais de France
  const requestBody = {
    text: text,
    model_id: 'eleven_v3',
    // language_code retir√© - eleven_v3 ne le supporte pas, la voix Iza a d√©j√† l'accent qu√©b√©cois
    // language_code: 'fr', // RETIR√â - for√ßait l'accent fran√ßais de France
    voice_settings: voiceSettings,
    output_format: 'mp3_44100_192'
  };

  const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
    method: 'POST',
    headers: {
      'Accept': 'audio/mpeg',
      'Content-Type': 'application/json',
      'xi-api-key': process.env.ELEVENLABS_API_KEY
    },
    body: JSON.stringify(requestBody)
  });

  if (!response.ok) {
    const errorBody = await response.text();
    console.error(`  ‚ùå ElevenLabs V3 API error:`, response.status, errorBody);
    throw new Error(`ElevenLabs V3 API error: ${response.status} - ${errorBody}`);
  }

  const audioBuffer = Buffer.from(await response.arrayBuffer());
  console.log(`  ‚úÖ Audio generated: ${audioBuffer.length} bytes (${(audioBuffer.length / 1024).toFixed(1)} KB)`);

  return audioBuffer;
}

/**
 * G√©n√®re l'audio complet avec ElevenLabs V3 et audio tags
 *
 * ARCHITECTURE V3:
 * 1. Ins√®re automatiquement les audio tags dans le texte
 * 2. Envoie le texte complet en un seul appel API
 * 3. V3 interpr√®te les tags pour expressivit√© naturelle
 *
 * Cette approche garantit:
 * - Respirations naturelles aux bons moments
 * - Soupirs apais√©s pour le rel√¢chement
 * - Ton doux et calme pour la m√©ditation
 * - Coh√©rence vocale sur toute la dur√©e
 */
async function generateMeditationAudio(text, guideType) {
  const isMeditation = guideType !== 'reflection';
  const type = isMeditation ? 'meditation' : 'reflection';

  const voiceId = VOICE_IDS[type];
  const voiceSettings = VOICE_SETTINGS[type];

  console.log(`üìù Original text length: ${text.length} chars`);
  console.log(`üé≠ Voice type: ${type}`);
  console.log(`ü§ñ Model: eleven_v3`);

  // Pr√©parer le texte avec audio tags
  const preparedText = prepareTextForV3(text, isMeditation);
  console.log(`üè∑Ô∏è Prepared text with audio tags: ${preparedText.length} chars`);

  // Log un aper√ßu du texte pr√©par√© (premiers 500 chars)
  console.log(`üìÑ Preview: ${preparedText.substring(0, 500)}...`);

  // G√©n√©rer l'audio avec V3
  const audioBuffer = await generateAudioV3(preparedText, voiceId, voiceSettings);

  console.log(`‚úÖ Final audio: ${audioBuffer.length} bytes (${(audioBuffer.length / 1024).toFixed(1)} KB)`);

  return audioBuffer;
}

// ============================================================================
// HANDLER PRINCIPAL
// ============================================================================

export default async function handler(req, res) {
  // üîê CORS S√âCURIS√â
  if (!handleCORS(req, res)) {
    return;
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // ‚ö° RATE LIMITING
  const rateLimit = checkRateLimit(req, '/api/audio');
  addRateLimitHeaders(res, { ...rateLimit, endpoint: '/api/audio' });

  if (!rateLimit.allowed) {
    console.warn(`üö´ Rate limit exceeded for audio`);
    return res.status(429).json({
      error: 'Too Many Requests',
      message: rateLimit.message,
      retryAfter: rateLimit.retryAfter
    });
  }

  try {
    const { text, guideType } = req.body;

    if (!text) {
      return res.status(400).json({ error: 'Missing text field' });
    }

    console.log('=== ELEVENLABS V3 AUDIO GENERATION ===');
    console.log('Guide Type:', guideType);
    console.log('Text length:', text.length, 'characters');

    // G√©n√©rer l'audio avec V3 et audio tags
    const audioBuffer = await generateMeditationAudio(text, guideType);

    // Convertir en base64
    const base64Audio = audioBuffer.toString('base64');

    console.log('=== GENERATION COMPLETE ===');

    res.status(200).json({ audio: base64Audio });

  } catch (error) {
    console.error('Error generating audio:', error);
    res.status(500).json({ error: 'Failed to generate audio', details: error.message });
  }
}
